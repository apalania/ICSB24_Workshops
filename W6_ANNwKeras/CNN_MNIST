{"cells":[{"cell_type":"markdown","metadata":{"id":"jYysdyb-CaWM"},"source":["# **Image Classification with Convolutional Neural Networks**"]},{"cell_type":"code","metadata":{"id":"9Z1UejUOHuyh"},"source":["import numpy as np                                                              # advanced math library\n","import matplotlib.pyplot as plt                                                 # MATLAB like plotting routines\n","import random                                                                   # for generating random numbers\n","\n","from keras.datasets import mnist                                                # MNIST dataset is included in Keras\n","from keras.models import Sequential                                             # Model type to be used\n","\n","from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten # Types of layers to be used in our model\n","                                                                                #from keras.utils import np_utils\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5FBWo4S6i0Q"},"source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)\n","print(x_train[0].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_DOO6Gb1J3GP"},"source":["Convolutional neural network (CNN) for the MNIST handwritten-digits image dataset\n","\n","Step 0. Load the data\n","\n","Step 1. Create the model: Specify the layers one-by-one, and then compile the model\n","\n","Step 2. Train the model and evaluate on the test set\n","\n","Step 3. Save the model, visualize error metrics over epochs to determine if the training has been successful\n"]},{"cell_type":"code","metadata":{"id":"WIQhAtP5JE8E"},"source":["x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0],28,28,1)\n","input_shape = (28,28,1)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /=255\n","x_test/=255\n","print('x_train shape:', x_train.shape)\n","print('Number of images in x_train', x_train.shape[0])\n","print('Number of images in x_test', x_test.shape[0])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_sKVtfKdKal8"},"source":["Model specification:\n","\n","Layer 1: 2d - Convolutional layer with 32 filters of size 5x5 each\n","\n","Layer 2: Max pooling layer with a pool size of 2x2\n","\n","Layer 3: 2d - Convolutional layer with 64 filters of size 5x5\n","\n","Layer 4: Max Pooling layer with size 2x2\n","\n","Layer 5: Flatten layer to convert the 2D matrix data to 1D vector before building Fully Connected layers\n","\n","Layer 6: Fully Connected (Dense) layer with 1024 neurons and relu activation function\n","\n","Layer 7: regularisation layer called Dropout. randomly exclude 20% of neurons in the layer to reduce overfitting\n","\n","Layer 8: Output layer -- 10 neurons for 10 classes with softmax activation to output probability predictions for each class.\n"]},{"cell_type":"code","metadata":{"id":"NtemSShBJ1_w"},"source":["\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"paKLUyJ-Ma7_"},"source":["model = Sequential()\n","model.add(Conv2D(32, kernel_size=(5,5), input_shape=input_shape))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(64,kernel_size=(5,5), input_shape=input_shape))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(10, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HW_9mVNUvqfN"},"source":["from tensorflow.keras.utils import plot_model\n","model.summary()\n","plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GY-rVa4N07Z"},"source":["#opt = SGD(lr=0.1, momentum=0.9)\n","#model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#adaptive moment estimation\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bD3ymHydOkii"},"source":["history = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=10, batch_size=1024, verbose=1)\n","_, acc = model.evaluate(x_test, y_test,verbose=0)\n","print(\"Model accuracy on the test set: {0:.3f}\".format(acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zKKC_bH2Y6D"},"source":["from matplotlib import pyplot\n","pyplot.subplot(211)\n","pyplot.title('Loss')\n","pyplot.plot(history.history['loss'], label='train')\n","pyplot.plot(history.history['val_loss'], label='test')\n","pyplot.legend()\n","pyplot.show()\n","pyplot.subplot(212)\n","pyplot.title('Accuracy')\n","pyplot.plot(history.history['accuracy'], label='train')\n","pyplot.plot(history.history['val_accuracy'], label='test')\n","pyplot.legend()\n","pyplot.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDE7-Ee4QoYC"},"source":["model.save('my_first_cnn_model.keras')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEo-2GokRAGQ"},"source":["from keras.models import load_model\n","model_new = load_model('my_first_cnn_model.keras')\n","#to evaluate a new dataset (with only the features):\n","#model_new.predict(new_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_new.predict(x_test)"],"metadata":{"id":"ukC5GNf89FIE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**CIFAR-10 Dataset with CNNs**\n","- The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class.\n","- There are 50000 training images and 10000 test images.\n"],"metadata":{"id":"YGsBmC5q7bms"}},{"cell_type":"code","source":["import os\n","import glob\n","\n","# Download the data\n","_URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n","zip_dir = tf.keras.utils.get_file('cifar-10-python.tar.gz', origin=_URL, extract=True)\n","\n","# Get the data and meta file names\n","data_dir = os.path.join(os.path.dirname(zip_dir), 'cifar-10-batches-py')\n","train_files = glob.glob(os.path.join(data_dir,\"data_batch_*\"))\n","test_file = os.path.join(data_dir,\"test_batch\")\n","meta_file = os.path.join(data_dir,\"batches.meta\")\n","\n","def unpickle(file):\n","    import pickle\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","\n","def build_dataset(files):\n","    x = []\n","    y = []\n","    for file in files:\n","        dict = unpickle(file)\n","        for image in dict[b'data']:\n","            # Image in the dataset is stored as a 3072 length 1D array\n","            x.append(image)\n","        for label in dict[b'labels']:\n","            y.append(label)\n","\n","    return tf.data.Dataset.from_tensor_slices((x,y))\n","\n","# Build the training dataset\n","train_dataset  = build_dataset(train_files)\n","\n","# Build the testing dataset\n","test_dataset = build_dataset([test_file])\n","\n","# Get the metadata\n","meta = unpickle(meta_file)"],"metadata":{"id":"ioKIZ6B87b6c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Train and Compile the model**"],"metadata":{"id":"FGudOXsN7lyT"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# Example training data (dummy data for illustration)\n","# Let's assume you have images with shape (50000 samples, 32 height, 32 width, 3 channels)\n","train_images = np.random.rand(50000, 32, 32, 3).astype('float32') * 255\n","train_labels = np.random.randint(0, 10, size=(50000,))\n","test_images = np.random.rand(10000, 32, 32, 3).astype('float32') * 255\n","test_labels = np.random.randint(0, 10, size=(10000,))\n","\n","# Create TensorFlow datasets\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n","\n","# Normalize and configure datasets\n","def reshape_and_normalize(images, labels):\n","    images = tf.cast(images / 255.0, tf.float32)                                # Normalize directly\n","    return images, labels\n","\n","train_dataset = train_dataset.map(reshape_and_normalize).cache().shuffle(50000).batch(32)\n","test_dataset = test_dataset.map(reshape_and_normalize).cache().batch(32)\n","\n","# Create and fit our model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n","    tf.keras.layers.MaxPool2D((2, 2), strides=2),\n","    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPool2D((2, 2), strides=2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(10)                                                   # Output layer for classification (10 classes)\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(train_dataset,\n","          epochs=10)\n","\n","# Evaluate the model with the test dataset\n","test_loss, test_accuracy = model.evaluate(test_dataset)\n","print(f'Test accuracy: {test_accuracy:.4f}')"],"metadata":{"id":"0IK65RrO78KM"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/rses-dl-course/rses-dl-course.github.io/blob/master/notebooks/python/L03_image_classification_with_cnn.ipynb","timestamp":1732678193946}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}